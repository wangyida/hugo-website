1
00:00:00,00 --> 00:00:11,00
We propose a method to reconstruct, complete and semantically label a 3D scene from a single depth image based on GAN.

2
00:00:11,03 --> 00:00:30,00
We use depth image as input and produce semantically labeled volumes. There are 12 categories in our experiments are based on SUNCG that includes: ceiling, floor, wall, window and so on. 

3
00:00:30,03 --> 00:01:04,00
The encoder for the given depth image compresses the input 2D image into a feature in the latent space. Its architecture is a concatenated network that sequentially combines 2D convolutional layers and max-pooling layers. The output of the encoder represents the latent feature of the semantic reconstruction architecture according to the given depth image.

4
00:01:04,03 --> 00:01:18,00
Then the generator unwraps the latent feature to a higher dimensional voxel data. The output of the generator is the voxel-wise classification for 12 categories represented in multiple channels.

5
00:01:18,03 --> 00:01:41,00
In summary, from the depth image to the 3D volume, our architecture is a concatenated structure of an encoder with 2D convolutional operators that convert the input depth image into a lower dimensional latent feature and a generator built with several 3D deconvolutional operators. 

6
00:01:41,03 --> 00:01:57,00
If we train this architecture directly, small objects can not be represented well, only common components could be predicted such as ceiling and floor.

7
00:01:57,03 --> 00:02:07,00
The wall and door are sparsely reconstructed, The sofa and chairs are even unrecognisable.

8
00:02:07,03 --> 00:02:22,00
Consider for the whole architecture which is concatenated with encoder and decoder. The latent feature is an important bridge between the given depth image and the expected semantic volumetric data.

9
00:02:22,03 --> 00:02:42,00
Since reconstructing from one image has a restrictive view of the scene, we want to make the latent features of the depth image to be similar to the feature extracted from complete volumetric data.

10
00:02:42,03 --> 00:02:51,00
We introduce discriminator D-l aiming at distinguishing the latent descriptors from each others.

11
00:02:51,03 --> 00:03:04,00
The output of both encoders are passed to the same generator, the resulting latent feature of depth image is similar to the feature of the semantic volumetric data. 

12
00:03:04,03 --> 00:03:17,00
With the help of latent discriminator, our inference architecture can provide more accurate semantic predictions for small objects with sharper edges.

13
00:03:17,03 --> 00:03:30,00
Based on these voxel representations, we can clearly visualize the superiority of our algorithm to reconstruct more detailed structures.

14
00:03:30,03 --> 00:03:42,00
Our method performs better than 3D VAE and 3D-RecGAN++ which are the recent works on 3D generative model used for generating 3D volumetric data.
