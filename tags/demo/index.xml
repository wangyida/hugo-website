<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>demo on Yida Wang</title>
    <link>https://example.com/tags/demo/</link>
    <description>Recent content in demo on Yida Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Aug 2020 10:15:01 +0200</lastBuildDate>
    
      <atom:link href="https://example.com/tags/demo/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>SoftPoolNet - Shape Descriptor for Point Cloud Completion and Classification</title>
        <link>https://example.com/2020/08/25/youtube/</link>
        <pubDate>Tue, 25 Aug 2020 10:15:01 +0200</pubDate>
        <guid>https://example.com/2020/08/25/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{DBLP:journals/corr/abs-2008-07358, author = {Yida Wang and David Joseph Tan and Nassir Navab and Federico Tombari}, title = {SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification}, journal = {CoRR}, volume = {abs/2008.07358}, year = {2020} } Abstrarct Point clouds are often the default choice for many applications as they exhibit more flexibility and efficiency than volumetric data. Nevertheless, their unorganized nature &amp;ndash; points are stored in an unordered way &amp;ndash; makes them less suited to be processed by deep learning pipelines.</description>
      </item>
    
      <item>
        <title>Xiaohan PhD applications</title>
        <link>https://example.com/2020/08/20/youtube/</link>
        <pubDate>Thu, 20 Aug 2020 10:15:01 +0200</pubDate>
        <guid>https://example.com/2020/08/20/youtube/</guid>
        <description>United States Harvard Department of Chemistry and Chemical Biology    Name email accept     Theodore Betley betley@chemistry.harvard.edu    Cynthia Friend friend@fas.harvard.edu    Eric Jacobsen jacobsen@chemistry.harvard.edu     Brown University Catalyst Design Lab    Name email accept     Andrew A Peterson Andrew_Peterson@brown.edu      Germany
RWTH Aachen Department of Chemistry and Chemical Biology    Name email accept    TU Berlin Institute of Chemistry    Name email accept     Inez Weidinger form    Peter Strasser pstrasser@tu-berlin.</description>
      </item>
    
      <item>
        <title>ForkNet - Multi-Branch Volumetric Semantic Completion From a Single Depth Image</title>
        <link>https://example.com/2019/11/01/youtube/</link>
        <pubDate>Fri, 01 Nov 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/11/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2019forknet, title={ForkNet: Multi-branch Volumetric Semantic Completion from a Single Depth Image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={Proceedings of the IEEE International Conference on Computer Vision}, pages={8608--8617}, year={2019} } Abstrarct We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space.</description>
      </item>
    
      <item>
        <title>Variational Object-aware 3D Hand Pose from a Single RGB Image</title>
        <link>https://example.com/2019/06/01/youtube/</link>
        <pubDate>Sat, 01 Jun 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/06/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image.</description>
      </item>
    
      <item>
        <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
        <link>https://example.com/2018/10/09/youtube/</link>
        <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
        <guid>https://example.com/2018/10/09/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning.</description>
      </item>
    
  </channel>
</rss>
