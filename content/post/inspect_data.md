
# Mask R-CNN  - 检查训练数据

检查并可视化数据加载和预处理代码。


```python
import os
import sys
import itertools
import math
import logging
import json
import re
import random
from collections import OrderedDict
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.lines as lines
from matplotlib.patches import Polygon

import utils
import visualize
from visualize import display_images
import model as modellib
from model import log

%matplotlib inline 

ROOT_DIR = os.getcwd()
```

    Using TensorFlow backend.


## 配置

运行下面的代码块之一来导入和加载要使用的配置。


```python
# Run one of the code blocks

# Shapes toy dataset
# import shapes
# config = shapes.ShapesConfig()

# MS COCO Dataset
import coco
config = coco.CocoConfig()
COCO_DIR = "path to COCO dataset"  # TODO: enter value here
```

## 数据集


```python
# 加载数据集
if config.NAME == 'shapes':
    dataset = shapes.ShapesDataset()
    dataset.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])
elif config.NAME == "coco":
    dataset = coco.CocoDataset()
    dataset.load_coco(COCO_DIR, "train")

# 在使用数据集之前必须调用
dataset.prepare()

print("Image Count: {}".format(len(dataset.image_ids)))
print("Class Count: {}".format(dataset.num_classes))
for i, info in enumerate(dataset.class_info):
    print("{:3}. {:50}".format(i, info['name']))
```

    loading annotations into memory...
    Done (t=11.93s)
    creating index...
    index created!
    Image Count: 82081
    Class Count: 81
      0. BG                                                
      1. person                                            
      2. bicycle                                           
      3. car                                               
      4. motorcycle                                        
      5. airplane                                          
      6. bus                                               
      7. train                                             
      8. truck                                             
      9. boat                                              
     10. traffic light                                     
     11. fire hydrant                                      
     12. stop sign                                         
     13. parking meter                                     
     14. bench                                             
     15. bird                                              
     16. cat                                               
     17. dog                                               
     18. horse                                             
     19. sheep                                             
     20. cow                                               
     21. elephant                                          
     22. bear                                              
     23. zebra                                             
     24. giraffe                                           
     25. backpack                                          
     26. umbrella                                          
     27. handbag                                           
     28. tie                                               
     29. suitcase                                          
     30. frisbee                                           
     31. skis                                              
     32. snowboard                                         
     33. sports ball                                       
     34. kite                                              
     35. baseball bat                                      
     36. baseball glove                                    
     37. skateboard                                        
     38. surfboard                                         
     39. tennis racket                                     
     40. bottle                                            
     41. wine glass                                        
     42. cup                                               
     43. fork                                              
     44. knife                                             
     45. spoon                                             
     46. bowl                                              
     47. banana                                            
     48. apple                                             
     49. sandwich                                          
     50. orange                                            
     51. broccoli                                          
     52. carrot                                            
     53. hot dog                                           
     54. pizza                                             
     55. donut                                             
     56. cake                                              
     57. chair                                             
     58. couch                                             
     59. potted plant                                      
     60. bed                                               
     61. dining table                                      
     62. toilet                                            
     63. tv                                                
     64. laptop                                            
     65. mouse                                             
     66. remote                                            
     67. keyboard                                          
     68. cell phone                                        
     69. microwave                                         
     70. oven                                              
     71. toaster                                           
     72. sink                                              
     73. refrigerator                                      
     74. book                                              
     75. clock                                             
     76. vase                                              
     77. scissors                                          
     78. teddy bear                                        
     79. hair drier                                        
     80. toothbrush                                        


## 显示样本

加载并显示原始图像和掩模图像。


```python
# Load and display random samples
image_ids = np.random.choice(dataset.image_ids, 4)
for image_id in image_ids:
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)
```


![png](output_7_0.png)



![png](output_7_1.png)



![png](output_7_2.png)



![png](output_7_3.png)


## 边界框

我们不是使用源数据集提供的边界框坐标，而是使用掩码来计算边界框。这使得我们无论源数据集如何都能够一致地处理边界框，并且还可以更轻松地调整大小，旋转或裁剪图像，因为我们只是从更新掩码生成边界框，而不是计算每种图像类型的边界框转换转型。


```python
# Load random image and mask.
image_id = random.choice(dataset.image_ids)
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print("image_id ", image_id, dataset.image_reference(image_id))
log("image", image)
log("mask", mask)
log("class_ids", class_ids)
log("bbox", bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
```

    image_id  74886 http://cocodataset.org/#explore?id=118535
    image                    shape: (375, 500, 3)         min:    0.00000  max:  255.00000
    mask                     shape: (375, 500, 5)         min:    0.00000  max:    1.00000
    class_ids                shape: (5,)                  min:    1.00000  max:   35.00000
    bbox                     shape: (5, 4)                min:    1.00000  max:  329.00000



![png](output_9_1.png)


## 调整图像大小

为了支持每批次的多个图像，图像被调整为一个尺寸（1024x1024）。纵横比保存，但。如果图像不是正方形，则会在顶部/底部或右侧/左侧添加零填充。


```python
# Load random image and mask.
image_id = np.random.choice(dataset.image_ids, 1)[0]
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)
original_shape = image.shape
# Resize
image, window, scale, padding = utils.resize_image(
    image, 
    min_dim=config.IMAGE_MIN_DIM, 
    max_dim=config.IMAGE_MAX_DIM,
    padding=config.IMAGE_PADDING)
mask = utils.resize_mask(mask, scale, padding)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print("image_id: ", image_id, dataset.image_reference(image_id))
print("Original shape: ", original_shape)
log("image", image)
log("mask", mask)
log("class_ids", class_ids)
log("bbox", bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
```

    /usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
      "the returned array has changed.", UserWarning)


    image_id:  6480 http://cocodataset.org/#explore?id=402563
    Original shape:  (476, 640, 3)
    image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000
    mask                     shape: (1024, 1024, 32)      min:    0.00000  max:    1.00000
    class_ids                shape: (32,)                 min:    1.00000  max:   77.00000
    bbox                     shape: (32, 4)               min:    1.00000  max:  991.00000



![png](output_11_2.png)


## 迷你掩模图像

使用高分辨率图像进行训练时，实例二进制蒙版可能会变大。例如，如果使用1024x1024映像训练，那么单个实例的掩码需要1MB的内存（Numpy使用字节作为布尔值）。如果一个图像有100个实例，那么只有100MB的掩码。

为了提高训练速度，我们通过以下方式优化口罩：
*我们存储对象边界框内的蒙版像素，而不是完整图像的蒙版。大多数物体与图像大小相比都很小，所以我们通过不在物体周围存储大量零来节省空间。
*我们将面罩调整为较小的尺寸（例如56x56）。对于大于所选大小的对象，我们会失去一点准确性。但是大多数对象注释的开头并不是很精确，所以对于大多数实际用途来说，这种损失是可以忽略的。可以在配置类中设置mini_mask的大小。

为了可视化掩码大小调整的效果，并验证代码的正确性，我们可以看到一些示例。


```python
image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(
    dataset, config, image_id, use_mini_mask=False)

log("image", image)
log("image_meta", image_meta)
log("class_ids", class_ids)
log("bbox", bbox)
log("mask", mask)

display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])
```

    image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000
    image_meta               shape: (89,)                 min:    0.00000  max: 23221.00000
    bbox                     shape: (1, 5)                min:   62.00000  max:  578.00000
    mask                     shape: (1024, 1024, 1)       min:    0.00000  max:    1.00000



![png](output_13_1.png)



```python
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
```


![png](output_14_0.png)



```python
# Add augmentation and mask resizing.
image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(
    dataset, config, image_id, augment=True, use_mini_mask=True)
log("mask", mask)
display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])
```

    mask                     shape: (56, 56, 1)           min:    0.00000  max:    1.00000



![png](output_15_1.png)



```python
mask = utils.expand_mask(bbox, mask, image.shape)
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
```


![png](output_16_0.png)


## 锚点

锚的顺序很重要。在训练和预测阶段使用相同的顺序。它必须匹配卷积执行的顺序。

对于一个FPN网络来说，定位锚点的方式必须能够很容易地将锚点与预测锚点分数和移位的卷积层输出相匹配。
*先按金字塔等级排序。第一级的所有锚点，然后是第二级的所有锚点，依此类推。这使得通过级别分离锚更容易。
*在每个级别中，按功能图处理顺序排序锚点。通常，卷积层处理从左上角开始并逐行向右移动的特征图。
*对于每个特征贴图单元格，为不同比例的锚点选择任何排序顺序。这里我们匹配传递给函数的比率顺序。

** 锚点跨度：**
在FPN架构中，前几层的特征映射是高分辨率的。例如，如果输入图像是1024x1024，那么第一层的特征meap是256x256，这会产生大约200K的锚（256 * 256 * 3）。这些锚点是32x32像素，它们相对于图像像素的步幅是4像素，所以有很多重叠。如果我们为特征映射中的每个其他单元生成锚，我们可以显着减少负载。例如，2的步幅会将锚的数量减少4。

在这个实现中，我们使用2的锚定步幅，这与纸张不同。


```python
# Generate Anchors
anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 
                                          config.RPN_ANCHOR_RATIOS,
                                          config.BACKBONE_SHAPES,
                                          config.BACKBONE_STRIDES, 
                                          config.RPN_ANCHOR_STRIDE)

# Print summary of anchors
num_levels = len(config.BACKBONE_SHAPES)
anchors_per_cell = len(config.RPN_ANCHOR_RATIOS)
print("Count: ", anchors.shape[0])
print("Scales: ", config.RPN_ANCHOR_SCALES)
print("ratios: ", config.RPN_ANCHOR_RATIOS)
print("Anchors per Cell: ", anchors_per_cell)
print("Levels: ", num_levels)
anchors_per_level = []
for l in range(num_levels):
    num_cells = config.BACKBONE_SHAPES[l][0] * config.BACKBONE_SHAPES[l][1]
    anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2)
    print("Anchors in Level {}: {}".format(l, anchors_per_level[l]))
```

    Count:  65472
    Scales:  (32, 64, 128, 256, 512)
    ratios:  [0.5, 1, 2]
    Anchors per Cell:  3
    Levels:  5
    Anchors in Level 0: 49152
    Anchors in Level 1: 12288
    Anchors in Level 2: 3072
    Anchors in Level 3: 768
    Anchors in Level 4: 192


Visualize anchors of one cell at the center of the feature map of a specific level.


```python
## Visualize anchors of one cell at the center of the feature map of a specific level

# Load and draw random image
image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id)
fig, ax = plt.subplots(1, figsize=(10, 10))
ax.imshow(image)
levels = len(config.BACKBONE_SHAPES)

for level in range(levels):
    colors = visualize.random_colors(levels)
    # Compute the index of the anchors at the center of the image
    level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels
    level_anchors = anchors[level_start:level_start+anchors_per_level[level]]
    print("Level {}. Anchors: {:6}  Feature map Shape: {}".format(level, level_anchors.shape[0], 
                                                                config.BACKBONE_SHAPES[level]))
    center_cell = config.BACKBONE_SHAPES[level] // 2
    center_cell_index = (center_cell[0] * config.BACKBONE_SHAPES[level][1] + center_cell[1])
    level_center = center_cell_index * anchors_per_cell 
    center_anchor = anchors_per_cell * (
        (center_cell[0] * config.BACKBONE_SHAPES[level][1] / config.RPN_ANCHOR_STRIDE**2) \
        + center_cell[1] / config.RPN_ANCHOR_STRIDE)
    level_center = int(center_anchor)

    # Draw anchors. Brightness show the order in the array, dark to bright.
    for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]):
        y1, x1, y2, x2 = rect
        p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor='none',
                              edgecolor=(i+1)*np.array(colors[level]) / anchors_per_cell)
        ax.add_patch(p)

```

    /usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
      "the returned array has changed.", UserWarning)


    Level 0. Anchors:  49152  Feature map Shape: [256 256]
    Level 1. Anchors:  12288  Feature map Shape: [128 128]
    Level 2. Anchors:   3072  Feature map Shape: [64 64]
    Level 3. Anchors:    768  Feature map Shape: [32 32]
    Level 4. Anchors:    192  Feature map Shape: [16 16]



![png](output_20_2.png)


## 数据生成器



```python
# Create data generator
random_rois = 2000
g = modellib.data_generator(
    dataset, config, shuffle=True, random_rois=random_rois, 
    batch_size=4,
    detection_targets=True)
```


```python
# Uncomment to run the generator through a lot of images
# to catch rare errors
# for i in range(1000):
#     print(i)
#     _, _ = next(g)
```


```python
# Get Next Image
if random_rois:
    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks, rpn_rois, rois], \
    [mrcnn_class_ids, mrcnn_bbox, mrcnn_mask] = next(g)
    
    log("rois", rois)
    log("mrcnn_class_ids", mrcnn_class_ids)
    log("mrcnn_bbox", mrcnn_bbox)
    log("mrcnn_mask", mrcnn_mask)
else:
    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_boxes, gt_masks], _ = next(g)
    
log("gt_class_ids", gt_class_ids)
log("gt_boxes", gt_boxes)
log("gt_masks", gt_masks)
log("rpn_match", rpn_match, )
log("rpn_bbox", rpn_bbox)
image_id = image_meta[0][0]
print("image_id: ", image_id, dataset.image_reference(image_id))

# Remove the last dim in mrcnn_class_ids. It's only added
# to satisfy Keras restriction on target shape.
mrcnn_class_ids = mrcnn_class_ids[:,:,0]
```

    /usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
      "the returned array has changed.", UserWarning)


    rois                     shape: (4, 128, 4)           min:    0.00000  max: 1023.00000
    mrcnn_class_ids          shape: (4, 128, 1)           min:    0.00000  max:   67.00000
    mrcnn_bbox               shape: (4, 128, 81, 5)       min:   -3.58824  max:    3.45455
    mrcnn_mask               shape: (4, 128, 28, 28, 81)  min:    0.00000  max:    1.00000
    gt_boxes                 shape: (4, 100, 5)           min:    0.00000  max: 1024.00000
    gt_masks                 shape: (4, 56, 56, 100)      min:    0.00000  max:    1.00000
    rpn_match                shape: (4, 65472, 1)         min:   -1.00000  max:    1.00000
    rpn_bbox                 shape: (4, 256, 4)           min:   -4.60969  max:    1.76777
    image_id:  2937 http://cocodataset.org/#explore?id=135453



```python
b = 0

# Restore original image (reverse normalization)
sample_image = modellib.unmold_image(normalized_images[b], config)

# Compute anchor shifts.
indices = np.where(rpn_match[b] == 1)[0]
refined_anchors = utils.apply_box_deltas(anchors[indices], rpn_bbox[b, :len(indices)] * config.RPN_BBOX_STD_DEV)
log("anchors", anchors)
log("refined_anchors", refined_anchors)

# Get list of positive anchors
positive_anchor_ids = np.where(rpn_match[b] == 1)[0]
print("Positive anchors: {}".format(len(positive_anchor_ids)))
negative_anchor_ids = np.where(rpn_match[b] == -1)[0]
print("Negative anchors: {}".format(len(negative_anchor_ids)))
neutral_anchor_ids = np.where(rpn_match[b] == 0)[0]
print("Neutral anchors: {}".format(len(neutral_anchor_ids)))

# ROI breakdown by class
for c, n in zip(dataset.class_names, np.bincount(mrcnn_class_ids[b].flatten())):
    if n:
        print("{:23}: {}".format(c[:20], n))

# Show positive anchors
visualize.draw_boxes(sample_image, boxes=anchors[positive_anchor_ids], 
                     refined_boxes=refined_anchors)
```

    anchors                  shape: (65472, 4)            min: -362.03867  max: 1258.03867
    refined_anchors          shape: (4, 4)                min:  112.99997  max:  912.00000
    Positive anchors: 4
    Negative anchors: 252
    Neutral anchors: 65216
    BG                     : 90
    chair                  : 6
    bed                    : 30
    remote                 : 2



![png](output_25_1.png)



```python
# Show negative anchors
visualize.draw_boxes(sample_image, boxes=anchors[negative_anchor_ids])
```


![png](output_26_0.png)



```python
# Show neutral anchors. They don't contribute to training.
visualize.draw_boxes(sample_image, boxes=anchors[np.random.choice(neutral_anchor_ids, 100)])
```


![png](output_27_0.png)


## ROIs


```python
if random_rois:
    # Class aware bboxes
    bbox_specific = mrcnn_bbox[b, np.arange(mrcnn_bbox.shape[1]), mrcnn_class_ids[b], :]

    # Refined ROIs
    refined_rois = utils.apply_box_deltas(rois[b].astype(np.float32), bbox_specific[:,:4] * config.BBOX_STD_DEV)

    # Class aware masks
    mask_specific = mrcnn_mask[b, np.arange(mrcnn_mask.shape[1]), :, :, mrcnn_class_ids[b]]

    visualize.draw_rois(sample_image, rois[b], refined_rois, mask_specific, mrcnn_class_ids[b], dataset.class_names)
    
    # Any repeated ROIs?
    rows = np.ascontiguousarray(rois[b]).view(np.dtype((np.void, rois.dtype.itemsize * rois.shape[-1])))
    _, idx = np.unique(rows, return_index=True)
    print("Unique ROIs: {} out of {}".format(len(idx), rois.shape[1]))
```

    Positive ROIs:  38
    Negative ROIs:  90
    Positive Ratio: 0.30
    Unique ROIs: 128 out of 128



![png](output_29_1.png)



```python
if random_rois:
    # Dispalay ROIs and corresponding masks and bounding boxes
    ids = random.sample(range(rois.shape[1]), 8)

    images = []
    titles = []
    for i in ids:
        image = visualize.draw_box(sample_image.copy(), rois[b,i,:4].astype(np.int32), [255, 0, 0])
        image = visualize.draw_box(image, refined_rois[i].astype(np.int64), [0, 255, 0])
        images.append(image)
        titles.append("ROI {}".format(i))
        images.append(mask_specific[i] * 255)
        titles.append(dataset.class_names[mrcnn_class_ids[b,i]][:20])

    display_images(images, titles, cols=4, cmap="Blues", interpolation="none")
```


![png](output_30_0.png)



```python
# Check ratio of positive ROIs in a set of images.
if random_rois:
    limit = 10
    temp_g = modellib.data_generator(
        dataset, config, shuffle=True, random_rois=10000, 
        batch_size=1, detection_targets=True)
    total = 0
    for i in range(limit):
        _, [ids, _, _] = next(temp_g)
        positive_rois = np.sum(ids[0] > 0)
        total += positive_rois
        print("{:5} {:5.2f}".format(positive_rois, positive_rois/ids.shape[1]))
    print("Average percent: {:.2f}".format(total/(limit*ids.shape[1])))
```

       42  0.33
       42  0.33


    /usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
      "the returned array has changed.", UserWarning)


       42  0.33
       42  0.33
       42  0.33
       42  0.33
       42  0.33
       42  0.33
       42  0.33
       42  0.33
    Average percent: 0.33

