<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications with demos on Yida Wang</title>
    <link>https://example.com/posts/</link>
    <description>Recent content in Publications with demos on Yida Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Aug 2020 10:15:01 +0200</lastBuildDate>
    
      <atom:link href="https://example.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>SoftPoolNet - Shape Descriptor for Point Cloud Completion and Classification</title>
        <link>https://example.com/2020/08/25/youtube/</link>
        <pubDate>Tue, 25 Aug 2020 10:15:01 +0200</pubDate>
        <guid>https://example.com/2020/08/25/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{DBLP:journals/corr/abs-2008-07358, author = {Yida Wang and David Joseph Tan and Nassir Navab and Federico Tombari}, title = {SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification}, journal = {CoRR}, volume = {abs/2008.07358}, year = {2020} } Abstrarct Point clouds are often the default choice for many applications as they exhibit more flexibility and efficiency than volumetric data. Nevertheless, their unorganized nature &amp;ndash; points are stored in an unordered way &amp;ndash; makes them less suited to be processed by deep learning pipelines.</description>
      </item>
    
      <item>
        <title>Xiaohan PhD applications</title>
        <link>https://example.com/2020/08/20/youtube/</link>
        <pubDate>Thu, 20 Aug 2020 10:15:01 +0200</pubDate>
        <guid>https://example.com/2020/08/20/youtube/</guid>
        <description>United States Harvard Department of Chemistry and Chemical Biology    Name email accept     Theodore Betley betley@chemistry.harvard.edu    Cynthia Friend friend@fas.harvard.edu    Eric Jacobsen jacobsen@chemistry.harvard.edu     Brown University Catalyst Design Lab    Name email accept     Andrew A Peterson Andrew_Peterson@brown.edu      Germany
RWTH Aachen Department of Chemistry and Chemical Biology    Name email accept    TU Berlin Institute of Chemistry    Name email accept     Inez Weidinger form    Peter Strasser pstrasser@tu-berlin.</description>
      </item>
    
      <item>
        <title>ForkNet - Multi-Branch Volumetric Semantic Completion From a Single Depth Image</title>
        <link>https://example.com/2019/11/01/youtube/</link>
        <pubDate>Fri, 01 Nov 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/11/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2019forknet, title={ForkNet: Multi-branch Volumetric Semantic Completion from a Single Depth Image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={Proceedings of the IEEE International Conference on Computer Vision}, pages={8608--8617}, year={2019} } Abstrarct We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space.</description>
      </item>
    
      <item>
        <title>Variational Object-aware 3D Hand Pose from a Single RGB Image</title>
        <link>https://example.com/2019/06/01/youtube/</link>
        <pubDate>Sat, 01 Jun 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/06/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image.</description>
      </item>
    
      <item>
        <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
        <link>https://example.com/2018/10/09/youtube/</link>
        <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
        <guid>https://example.com/2018/10/09/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning.</description>
      </item>
    
      <item>
        <title>Generative Model with Coordinate Metric Learning for Object Recognition Based on 3D Models</title>
        <link>https://example.com/2017/11/15/youtube/</link>
        <pubDate>Wed, 15 Nov 2017 10:15:01 +0200</pubDate>
        <guid>https://example.com/2017/11/15/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{wang2018generative, title={Generative Model With Coordinate Metric Learning for Object Recognition Based on 3D Models}, author={Wang, Yida and Deng, Weihong}, journal={IEEE Transactions on Image Processing}, volume={27}, number={12}, pages={5813--5826}, year={2018}, publisher={IEEE} } Abstrarct Collecting data for deep learning is so tedious which makes it hard to establish a perfect database. In this paper, we propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more sundry.</description>
      </item>
    
      <item>
        <title>Self-restraint Object Recognition by Model Based CNN Learning</title>
        <link>https://example.com/2016/04/01/youtube/</link>
        <pubDate>Fri, 01 Apr 2016 10:15:01 +0200</pubDate>
        <guid>https://example.com/2016/04/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2016self, title={Self-restraint object recognition by model based CNN learning}, author={Wang, Yida and Deng, Weihong}, booktitle={2016 IEEE International Conference on Image Processing (ICIP)}, pages={654--658}, year={2016}, organization={IEEE} } Abstrarct CNN has shown excellent performance on object recognition based on huge amount of real images. For training with synthetic data rendered from 3D models alone to reduce the workload of collecting real images, we propose a concatenated self-restraint learning structure lead by a triplet and softmax jointed loss function for object recognition.</description>
      </item>
    
      <item>
        <title>Zigzagnet- Efficient deep learning for real object recognition based on 3D models</title>
        <link>https://example.com/2016/04/01/youtube/</link>
        <pubDate>Fri, 01 Apr 2016 10:15:01 +0200</pubDate>
        <guid>https://example.com/2016/04/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2016zigzagnet, title={Zigzagnet: Efficient deep learning for real object recognition based on 3D models}, author={Wang, Yida and Cui, Can and Zhou, Xiuzhuang and Deng, Weihong}, booktitle={Asian Conference on Computer Vision}, pages={456--471}, year={2016}, organization={Springer} }	Abstrarct Effective utilization on texture-less 3D models for deep learning is significant to recognition on real photos. We eliminate the reliance on massive real training data by modifying convolutional neural network in 3 aspects: synthetic data rendering for training data generation in large quantities, multi-triplet cost function modification for multi-task learning and compact micro architecture design for producing tiny parametric model while overcoming over-fit problem in texture-less models.</description>
      </item>
    
  </channel>
</rss>
