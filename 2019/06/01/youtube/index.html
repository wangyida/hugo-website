<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Variational Object-aware 3D Hand Pose from a Single RGB Image - Yida Wang</title>
  <meta name="author" content="Yida Wang">
  <meta name="description" content="A blog about everything.">

  <meta name="generator" content="Hugo 0.68.3" />

  
  
  
  
  
  <link rel="stylesheet" href="/assets/css/external.min.css" media="screen">

  
  
  <link rel="stylesheet" href="/assets/css/styles.css" media="screen">

  <link href="//fonts.googleapis.com/css?family=Roboto:400" rel="stylesheet">

  
  
  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/src/images/apple-touch-icon.png">
  <link rel="shortcut icon" href="/src/images/favicon.ico">

  
  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="Yida Wang" />
  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="Yida Wang" />

  <meta property="og:title" content="Variational Object-aware 3D Hand Pose from a Single RGB Image" />
<meta property="og:description" content="If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.com/2019/06/01/youtube/" />
<meta property="article:published_time" content="2019-06-01T10:15:01+02:00" />
<meta property="article:modified_time" content="2019-06-01T10:15:01+02:00" />

  
  <meta itemprop="name" content="Variational Object-aware 3D Hand Pose from a Single RGB Image">
<meta itemprop="description" content="If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image.">
<meta itemprop="datePublished" content="2019-06-01T10:15:01&#43;02:00" />
<meta itemprop="dateModified" content="2019-06-01T10:15:01&#43;02:00" />
<meta itemprop="wordCount" content="231">



<meta itemprop="keywords" content="machine learning,demo,tracking,robotics," />
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Variational Object-aware 3D Hand Pose from a Single RGB Image"/>
<meta name="twitter:description" content="If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image."/>

</head>

  <body>
    
      <nav>
  <a href="/" title="Homepage">
    Simplicity
  </a>
</nav>

    
    <main class="container">
      
  <article>
    <header>
      <small>
        <time datetime="2019-06-01 10:15:01&#43;0200">2019-06-01</time>
          &bull;
          
            
            <a href="/categories/publication">PUBLICATION</a>
          </small>
      <h1>Variational Object-aware 3D Hand Pose from a Single RGB Image</h1>
    </header>
    <section><div class="embed-container">
  <iframe src="https://www.youtube.com/embed/tSTQ2NTqB4A" frameborder="0" allowfullscreen></iframe>
</div>

<p>If you find this work useful in yourr research, please cite:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">@article<span class="o">{</span>gao2019variational,
  <span class="nv">title</span><span class="o">={</span>Variational Object-Aware 3-D Hand Pose From a Single RGB Image<span class="o">}</span>,
  <span class="nv">author</span><span class="o">={</span>Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico<span class="o">}</span>,
  <span class="nv">journal</span><span class="o">={</span>IEEE Robotics and Automation Letters<span class="o">}</span>,
  <span class="nv">volume</span><span class="o">={</span>4<span class="o">}</span>,
  <span class="nv">number</span><span class="o">={</span>4<span class="o">}</span>,
  <span class="nv">pages</span><span class="o">={</span>4239--4246<span class="o">}</span>,
  <span class="nv">year</span><span class="o">={</span>2019<span class="o">}</span>,
  <span class="nv">publisher</span><span class="o">={</span>IEEE<span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h1 id="abstrarct">Abstrarct</h1>
<p>We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image.  Our approach is based on a probabilistic model implemented with deep architectures, which is used for regressing, respectively, the 2D hand joints heat maps and the 3D hand joints coordinates.  We train our networks so to make our approach robust to large object- and self-occlusions, as commonly occurring with the task at hand. Using specialized latent variables, the deep architecture internally infers the category of the grasped object so to enhance the 3D reconstruction, based on the underlying assumption that objects of a similar category, i.e. with similar shape and size, are grasped in a similar way. Moreover, given the scarcity of 3D hand-object manipulation benchmarks with joint annotations, we propose a new annotated synthetic dataset with realistic images, hand masks, joint masks and 3D joints coordinates. Our approach is flexible as it does not require depth information, sensor calibration, data gloves, or finger markers.  We quantitatively evaluate it on synthetic datasets achieving stateof-the-art accuracy, as well as qualitatively on real sequences.</p>
</section>
    <footer>
      <hr>
      <div class="meta">
        <p class="tags">
          
            
              <a href="/tags/machine-learning">
                <span>#</span>machine learning</a>
            
              <a href="/tags/demo">
                <span>#</span>demo</a>
            
              <a href="/tags/tracking">
                <span>#</span>tracking</a>
            
              <a href="/tags/robotics">
                <span>#</span>robotics</a>
            
          
        </p>
      </div>
      <hr>
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "test" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </footer>
  </article>

    </main>
    
      <footer>
  <p>
    &copy; 2020 Yida Wang. <a href="http://creativecommons.org/licenses/by-sa/4.0/">Some Rights Reserved</a>.
  </p>
  <p>
    Powered by <a href="https://gohugo.io" title="A Fast and Flexible Website Generator">Hugo</a> &amp; <a href="https://github.com/eshlox/simplicity" title="Hugo theme">Simplicity</a>.
  </p>
</footer>

    
    
    
    
    
    
    
    <script src="/assets/js/scripts.min.js"></script>
    
  </body>
</html>
