<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Adversarial Semantic Scene Completion from a Single Depth Image - Yida Wang</title>
  <meta name="author" content="Yida Wang">
  <meta name="description" content="A blog about everything.">

  <meta name="generator" content="Hugo 0.68.3" />

  
  
  
  
  
  <link rel="stylesheet" href="/assets/css/external.min.css" media="screen">

  
  
  <link rel="stylesheet" href="/assets/css/styles.css" media="screen">

  <link href="//fonts.googleapis.com/css?family=Roboto:400" rel="stylesheet">

  
  
  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/src/images/apple-touch-icon.png">
  <link rel="shortcut icon" href="/src/images/favicon.ico">

  
  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="Yida Wang" />
  <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="Yida Wang" />

  <meta property="og:title" content="Adversarial Semantic Scene Completion from a Single Depth Image" />
<meta property="og:description" content="If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.com/2018/10/09/youtube/" />
<meta property="article:published_time" content="2018-10-09T10:15:01+02:00" />
<meta property="article:modified_time" content="2018-10-09T10:15:01+02:00" />

  
  <meta itemprop="name" content="Adversarial Semantic Scene Completion from a Single Depth Image">
<meta itemprop="description" content="If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning.">
<meta itemprop="datePublished" content="2018-10-09T10:15:01&#43;02:00" />
<meta itemprop="dateModified" content="2018-10-09T10:15:01&#43;02:00" />
<meta itemprop="wordCount" content="205">



<meta itemprop="keywords" content="machine learning,demo,computer vision," />
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Adversarial Semantic Scene Completion from a Single Depth Image"/>
<meta name="twitter:description" content="If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning."/>

</head>

  <body>
    
      <nav>
  <a href="/" title="Homepage">
    Simplicity
  </a>
</nav>

    
    <main class="container">
      
  <article>
    <header>
      <small>
        <time datetime="2018-10-09 10:15:01&#43;0200">2018-10-09</time>
          &bull;
          
            
            <a href="/categories/publication">PUBLICATION</a>
          </small>
      <h1>Adversarial Semantic Scene Completion from a Single Depth Image</h1>
    </header>
    <section><div class="embed-container">
  <iframe src="https://www.youtube.com/embed/udvBhkupwXE" frameborder="0" allowfullscreen></iframe>
</div>

<p>If you find this work useful in yourr research, please cite:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">@inproceedings<span class="o">{</span>wang2018adversarial,
  <span class="nv">title</span><span class="o">={</span>Adversarial semantic scene completion from a single depth image<span class="o">}</span>,
  <span class="nv">author</span><span class="o">={</span>Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico<span class="o">}</span>,
  <span class="nv">booktitle</span><span class="o">={</span><span class="m">2018</span> International Conference on 3D Vision <span class="o">(</span>3DV<span class="o">)}</span>,
  <span class="nv">pages</span><span class="o">={</span>426--434<span class="o">}</span>,
  <span class="nv">year</span><span class="o">={</span>2018<span class="o">}</span>,
  <span class="nv">organization</span><span class="o">={</span>IEEE<span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h1 id="abstrarct">Abstrarct</h1>
<p>We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning. In particular, we suggest using multiple adversarial loss terms that not only enforce realistic outputs with respect to the ground truth, but also an effective embedding of the internal features. This is done by correlating the latent features of the encoder working on partial 2.5D data with the latent features extracted from a variational 3D autoencoder trained to reconstruct the complete semantic scene.  In addition, differently from other approaches that operate entirely through 3D convolutions, at test time we retain the original 2.5D structure of the input during downsampling to improve the effectiveness of the internal representation of our model. We test our approach on the main benchmark datasets for semantic scene completion to qualitatively and quantitatively assess the effectiveness of our proposal.</p>
</section>
    <footer>
      <hr>
      <div class="meta">
        <p class="tags">
          
            
              <a href="/tags/machine-learning">
                <span>#</span>machine learning</a>
            
              <a href="/tags/demo">
                <span>#</span>demo</a>
            
              <a href="/tags/computer-vision">
                <span>#</span>computer vision</a>
            
          
        </p>
      </div>
      <hr>
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "test" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </footer>
  </article>

    </main>
    
      <footer>
  <p>
    &copy; 2020 Yida Wang. <a href="http://creativecommons.org/licenses/by-sa/4.0/">Some Rights Reserved</a>.
  </p>
  <p>
    Powered by <a href="https://gohugo.io" title="A Fast and Flexible Website Generator">Hugo</a> &amp; <a href="https://github.com/eshlox/simplicity" title="Hugo theme">Simplicity</a>.
  </p>
</footer>

    
    
    
    
    
    
    
    <script src="/assets/js/scripts.min.js"></script>
    
  </body>
</html>
